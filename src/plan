Hexapod training:
# TODO: Try learning leg model in air using random policy and see if the model regression is as accurate under a different policy (non-random)
# TODO: Add callback for id and NOTE reporting.
# TODO: Add callback for symmetry penalty using gradient descent
# TODO: Keep training straight and stairs policy
# TODO: Make checkpoint and best model copier from goedel
# TODO: Make proper input argument parser

Hexapod HW:
# TODO: Make contact sensors
# TODO: Make contact + dampeners in CAD software
# TODO: Integrate T265 (both hardware and SW)
# TODO: Test how much energy each servo consumes in total and compare with simulation

Adaptation research:
# TODO: Fix up an adaptation env (hangpole probably) for adaptation testing <- current
# TODO: Model based learning from a small amount of examples regularized by simulated examples
# TODO: Goal: Learn how to meta learn for supervised learning and RL
# TODO: Try meta learning (MAML and meta learning exploration) for supervised learning of transition probabilities

Research: Steps
# TODO: Prepare environments for training and testing. All environments must be in the same form as gym, but also sample-able upon reset
# TODO: Environments are utimately the following: Cartpole, Cartpole swing up, Hexapod, Quadcopter stabilize, Quadcopter waypoints, Buggie, Airplane waypoints, Airplane land, Sailboat waypoint
# TODO: Test model learning for all envs. Is random exploration enough? How does a randomly trained model performance generalize to
# TODO: a state distribution induced by a policy learned by RL? Does learning using state visitation stratification help? Also compare to
# TODO: learning a model and a policy at the same time so that we are sampling from a relevant state distribution
# TODO: Can a model learning using RNN adapt to various parameter changes?
# TODO: Make a MAML and/or ANIL implementation which accepts our environments as input

Paper:
# TODO: 1 per day

Quad:
# TODO: Add feedforward reg to compensate yaw effect when pitching or rolling. Test Quad

Car HW:
# TODO: Start integrating hardware

Room pi:
# TODO: Install necessary stuff on pi
# TODO: Add and test night camera
# TODO: Install PI near bed

# VIR Projects:
1) Learning model of fast RC buggie using script which gathers data and using it to
   learn a forward function of the buggie using supervised learning.
2) Learning online stabilizing or flying for real quadcopter
3) Control of real car or quad using RL
4) Model based planning control of a KUKA robot using learned model and gradient descent
